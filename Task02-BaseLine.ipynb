{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import torch.utils.data as ud\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as ud\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行数据扩展\n",
    "\n",
    "class SVHDataset(ud.Dataset):\n",
    "    def __init__(self, img_pattern, label_folder, transform=None):\n",
    "        self.img_path = glob.glob(img_pattern)\n",
    "        self.img_label = [v['label'] for k,v in json.load(open(label_folder)).items()]\n",
    "        self.img_path.sort()\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        实现了切片方法的获取\n",
    "        \"\"\"\n",
    "        # 批量读取数据\n",
    "        imgs = Image.open(self.img_path[index]).convert('RGB')\n",
    "        if self.transform:\n",
    "            imgs = self.transform(imgs)\n",
    "        # 将原始数据分类10为0, 保证有五位数字\n",
    "        # example: [10]*2 = [10, 10], [2, 3] + [10] = [2, 3, 10]\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        lbl = list(lbl) + (5 - len(lbl))*[10]\n",
    "        return imgs, torch.Tensor(lbl[:5])\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据扩充和训练规范化\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "                # 缩放到固定尺⼨\n",
    "                transforms.Resize((64, 128)),\n",
    "                # 随机颜⾊变换\n",
    "                # tv.transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "                # 加⼊随机旋转\n",
    "                transforms.RandomRotation(15),\n",
    "                # 将图⽚转换为pytorch 的tesntor\n",
    "                transforms.ToTensor(),\n",
    "                # 对图像像素进⾏归⼀化\n",
    "                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ]),\n",
    "    'val': transforms.Compose([\n",
    "                # 缩放到固定尺⼨\n",
    "                transforms.Resize((64, 128)),\n",
    "                transforms.CenterCrop((64, 128)),\n",
    "                # 加⼊随机旋转\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                # 将图⽚转换为pytorch 的tesntor\n",
    "                transforms.ToTensor(),\n",
    "                # 对图像像素进⾏归⼀化\n",
    "                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "            ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 50\n",
    "USE_CUDA = True\n",
    "\n",
    "train_loader = ud.DataLoader(\n",
    "    dataset=SVHDataset('Datasets/mchar_train/*.png', 'Datasets/mchar_train.json', data_transforms['train']),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    # num_workers 在windows上报错 设置改为 0\n",
    "    num_workers= (0 if sys.platform.startswith('win') else 10)\n",
    ")\n",
    "val_loader = ud.DataLoader(\n",
    "    dataset=SVHDataset('Datasets/mchar_val/*.png', 'Datasets/mchar_val.json', data_transforms['val']),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    # num_workers 在windows上报错 设置改为 0\n",
    "    num_workers= (0 if sys.platform.startswith('win') else 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# 初始化构建线性网络\n",
    "class SVHN_Model(torch.nn.Module):\n",
    "    def __init__(self, path=None):\n",
    "        super(SVHN_Model, self).__init__()\n",
    "        if path is None:\n",
    "            model_conv = models.resnet18(pretrained=True)\n",
    "        else:\n",
    "            model_conv = models.resnet18(pretrained=False)\n",
    "            model_conv.load_state_dict(torch.load(path))\n",
    "        model_conv.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        model_conv = torch.nn.Sequential(*list(model_conv.children())[:-1])\n",
    "        self.cnn = model_conv\n",
    "        # 每个字符有11中情况\n",
    "        self.fc1 = torch.nn.Linear(512, 11)\n",
    "        self.fc2 = torch.nn.Linear(512, 11)\n",
    "        self.fc3 = torch.nn.Linear(512, 11)\n",
    "        self.fc4 = torch.nn.Linear(512, 11)\n",
    "        self.fc5 = torch.nn.Linear(512, 11)\n",
    "    def forward(self, img):\n",
    "        # activation function for\n",
    "        feat = self.cnn(img)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        return c1, c2, c3, c4, c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def train_def(train_loader, model, loss_func, optimizer):\n",
    "    \n",
    "    # 切换模型为训练模式\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        # train your data...\n",
    "        if USE_CUDA:\n",
    "            batch_x = batch_x.cuda()\n",
    "            # 将 float32 强制转换为 long\n",
    "            batch_y = batch_y.long().cuda()\n",
    "        predicate = model(batch_x)\n",
    "        loss = reduce(lambda x, y: x + y, [loss_func(predicate[m], batch_y[:, m]) for m in range(batch_y.shape[1])])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "        \n",
    "def validate_def(val_loader, model, loss_func):\n",
    "    # 切换模型为预测模型\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    # 不记录模型梯度信息\n",
    "    with torch.no_grad():\n",
    "        for step, (batch_x, batch_y) in enumerate(val_loader):\n",
    "            if USE_CUDA:\n",
    "                batch_x = batch_x.cuda()\n",
    "                # 将 float32 强制转换为 long\n",
    "                batch_y = batch_y.long().cuda()\n",
    "            predicate = model(batch_x)\n",
    "            loss = reduce(lambda x, y: x + y, [loss_func(predicate[m], batch_y[:, m]) for m in range(batch_y.shape[1])])\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)\n",
    "\n",
    "def predict_def(test_loader, model, tta=10):\n",
    "    \n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "\n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for step, (batch_x, batch_y) in enumerate(test_loader):\n",
    "                if USE_CUDA:\n",
    "                    batch_x = batch_x.cuda()\n",
    "\n",
    "                c0, c1, c2, c3, c4 = model(batch_x)\n",
    "                if USE_CUDA:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.cpu().numpy(), \n",
    "                        c1.data.cpu().numpy(),\n",
    "                        c2.data.cpu().numpy(), \n",
    "                        c3.data.cpu().numpy(),\n",
    "                        c4.data.cpu().numpy()], axis=1)\n",
    "                else:\n",
    "                    output = np.concatenate([\n",
    "                        c0.data.numpy(), \n",
    "                        c1.data.numpy(),\n",
    "                        c2.data.numpy(), \n",
    "                        c3.data.numpy(),\n",
    "                        c4.data.numpy()], axis=1)\n",
    "\n",
    "                test_pred.append(output)\n",
    "\n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "\n",
    "    return test_pred_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 13.08302174727122 \t Val loss: 13.217922539711\n",
      "Val Acc 0.0\n",
      "Find better model in Epoch 0, saving model.\n"
     ]
    }
   ],
   "source": [
    "model = SVHN_Model(path='resnet18-5c106cde.pth')  # define the network\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "# 开启训练模式\n",
    "\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), 0.001)\n",
    "# the target label is NOT an one-hotted\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "best_loss = 1000.0\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    train_loss = train_def(train_loader, model, loss_func, optimizer)\n",
    "    val_loss = validate_def(val_loader, model, loss_func)\n",
    "\n",
    "    val_label = [''.join(map(str, x)) for x in val_loader.dataset.img_label]\n",
    "    val_predict_label = predict_def(val_loader, model, 1)\n",
    "    # 将其平铺水平获取值最大的一个\n",
    "    val_predict_label = np.vstack([\n",
    "        val_predict_label[:, :11].argmax(1),\n",
    "        val_predict_label[:, 11:22].argmax(1),\n",
    "        val_predict_label[:, 22:33].argmax(1),\n",
    "        val_predict_label[:, 33:44].argmax(1),\n",
    "        val_predict_label[:, 44:55].argmax(1),\n",
    "    ]).T\n",
    "    val_label_pred = []\n",
    "    for x in val_predict_label:\n",
    "        \n",
    "        val_label_pred.append(''.join(map(str, x[x!=10])))\n",
    "\n",
    "    val_char_acc = np.mean(np.array(val_label_pred) == np.array(val_label))\n",
    "\n",
    "    print('Epoch: {0}, Train loss: {1} \\t Val loss: {2}'.format(epoch, train_loss, val_loss))\n",
    "    print('Val Acc', val_char_acc)\n",
    "    # 记录下验证集精度\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        print('Find better model in Epoch {0}, saving model.'.format(epoch))\n",
    "        torch.save(model.state_dict(), './model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
